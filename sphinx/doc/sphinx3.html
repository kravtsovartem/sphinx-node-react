<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Sphinx 3 manual</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      .smallcaps{font-variant: small-caps;}
      .line-block{white-space: pre-line;}
      .column{display: inline-block;}
  </style>
  <style type="text/css">
div.sourceLine, a.sourceLine { display: inline-block; min-height: 1.25em; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; }
@media print {
code.sourceCode { white-space: pre-wrap; }
div.sourceLine, a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource div.sourceLine, .numberSource a.sourceLine
  { position: relative; }
pre.numberSource div.sourceLine::before, .numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em; }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; color: #aaaaaa;  padding-left: 4px; }
@media screen {
a.sourceLine::before { text-decoration: underline; color = initial; }
}
code span.kw { color: #0000ff; } /* Keyword */
code span.ch { color: #008080; } /* Char */
code span.st { color: #008080; } /* String */
code span.co { color: #008000; } /* Comment */
code span.ot { color: #ff4000; } /* Other */
code span.al { color: #ff0000; } /* Alert */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.wa { color: #008000; font-weight: bold; } /* Warning */
code span.cn { } /* Constant */
code span.sc { color: #008080; } /* SpecialChar */
code span.vs { color: #008080; } /* VerbatimString */
code span.ss { color: #008080; } /* SpecialString */
code span.im { } /* Import */
code span.va { } /* Variable */
code span.cf { color: #0000ff; } /* ControlFlow */
code span.op { } /* Operator */
code span.bu { } /* BuiltIn */
code span.ex { } /* Extension */
code span.pp { color: #ff4000; } /* Preprocessor */
code span.do { color: #008000; } /* Documentation */
code span.an { color: #008000; } /* Annotation */
code span.cv { color: #008000; } /* CommentVar */
code span.at { } /* Attribute */
code span.in { color: #008000; } /* Information */
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style type="text/css">
  
  /* based on https://gist.github.com/dashed/6714393 */
  /*! normalize.css v2.1.3 | MIT License | git.io/normalize */
  
  /* ==========================================================================
     HTML5 display definitions
     ========================================================================== */
  
  /**
   * Correct `block` display not defined in IE 8/9.
   */
  
  article,
  aside,
  details,
  figcaption,
  figure,
  footer,
  header,
  hgroup,
  main,
  nav,
  section,
  summary {
      display: block;
  }
  
  /**
   * Correct `inline-block` display not defined in IE 8/9.
   */
  
  audio,
  canvas,
  video {
      display: inline-block;
  }
  
  /**
   * Prevent modern browsers from displaying `audio` without controls.
   * Remove excess height in iOS 5 devices.
   */
  
  audio:not([controls]) {
      display: none;
      height: 0;
  }
  
  /**
   * Address `[hidden]` styling not present in IE 8/9.
   * Hide the `template` element in IE, Safari, and Firefox < 22.
   */
  
  [hidden],
  template {
      display: none;
  }
  
  /* ==========================================================================
     Base
     ========================================================================== */
  
  /**
   * 1. Set default font family to sans-serif.
   * 2. Prevent iOS text size adjust after orientation change, without disabling
   *    user zoom.
   */
  
  html {
      font-family: sans-serif; /* 1 */
      -ms-text-size-adjust: 100%; /* 2 */
      -webkit-text-size-adjust: 100%; /* 2 */
  }
  
  /**
   * Remove default margin.
   */
  
  body {
      margin: 0;
  }
  
  /* ==========================================================================
     Links
     ========================================================================== */
  
  /**
   * Remove the gray background color from active links in IE 10.
   */
  
  a {
      background: transparent;
  }
  
  /**
   * Address `outline` inconsistency between Chrome and other browsers.
   */
  
  a:focus {
      outline: thin dotted;
  }
  
  /**
   * Improve readability when focused and also mouse hovered in all browsers.
   */
  
  a:active,
  a:hover {
      outline: 0;
  }
  
  /* ==========================================================================
     Typography
     ========================================================================== */
  
  /**
   * Address variable `h1` font-size and margin within `section` and `article`
   * contexts in Firefox 4+, Safari 5, and Chrome.
   */
  
  h1 {
      font-size: 2em;
      margin: 0.67em 0;
  }
  
  /**
   * Address styling not present in IE 8/9, Safari 5, and Chrome.
   */
  
  abbr[title] {
      border-bottom: 1px dotted;
  }
  
  /**
   * Address style set to `bolder` in Firefox 4+, Safari 5, and Chrome.
   */
  
  b,
  strong {
      font-weight: bold;
  }
  
  /**
   * Address styling not present in Safari 5 and Chrome.
   */
  
  dfn {
      font-style: italic;
  }
  
  /**
   * Address differences between Firefox and other browsers.
   */
  
  hr {
      -moz-box-sizing: content-box;
      box-sizing: content-box;
      height: 0;
  }
  
  /**
   * Address styling not present in IE 8/9.
   */
  
  mark {
      background: #ff0;
      color: #000;
  }
  
  /**
   * Correct font family set oddly in Safari 5 and Chrome.
   */
  
  code,
  kbd,
  pre,
  samp {
      font-family: monospace, serif;
      font-size: 1em;
  }
  
  /**
   * Improve readability of pre-formatted text in all browsers.
   */
  
  pre {
      white-space: pre-wrap;
  }
  
  /**
   * Set consistent quote types.
   */
  
  q {
      quotes: "\201C" "\201D" "\2018" "\2019";
  }
  
  /**
   * Address inconsistent and variable font size in all browsers.
   */
  
  small {
      font-size: 80%;
  }
  
  /**
   * Prevent `sub` and `sup` affecting `line-height` in all browsers.
   */
  
  sub,
  sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
  }
  
  sup {
      top: -0.5em;
  }
  
  sub {
      bottom: -0.25em;
  }
  
  /* ==========================================================================
     Embedded content
     ========================================================================== */
  
  /**
   * Remove border when inside `a` element in IE 8/9.
   */
  
  img {
      border: 0;
  }
  
  /**
   * Correct overflow displayed oddly in IE 9.
   */
  
  svg:not(:root) {
      overflow: hidden;
  }
  
  /* ==========================================================================
     Figures
     ========================================================================== */
  
  /**
   * Address margin not present in IE 8/9 and Safari 5.
   */
  
  figure {
      margin: 0;
  }
  
  /* ==========================================================================
     Forms
     ========================================================================== */
  
  /**
   * Define consistent border, margin, and padding.
   */
  
  fieldset {
      border: 1px solid #c0c0c0;
      margin: 0 2px;
      padding: 0.35em 0.625em 0.75em;
  }
  
  /**
   * 1. Correct `color` not being inherited in IE 8/9.
   * 2. Remove padding so people aren't caught out if they zero out fieldsets.
   */
  
  legend {
      border: 0; /* 1 */
      padding: 0; /* 2 */
  }
  
  /**
   * 1. Correct font family not being inherited in all browsers.
   * 2. Correct font size not being inherited in all browsers.
   * 3. Address margins set differently in Firefox 4+, Safari 5, and Chrome.
   */
  
  button,
  input,
  select,
  textarea {
      font-family: inherit; /* 1 */
      font-size: 100%; /* 2 */
      margin: 0; /* 3 */
  }
  
  /**
   * Address Firefox 4+ setting `line-height` on `input` using `!important` in
   * the UA stylesheet.
   */
  
  button,
  input {
      line-height: normal;
  }
  
  /**
   * Address inconsistent `text-transform` inheritance for `button` and `select`.
   * All other form control elements do not inherit `text-transform` values.
   * Correct `button` style inheritance in Chrome, Safari 5+, and IE 8+.
   * Correct `select` style inheritance in Firefox 4+ and Opera.
   */
  
  button,
  select {
      text-transform: none;
  }
  
  /**
   * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
   *    and `video` controls.
   * 2. Correct inability to style clickable `input` types in iOS.
   * 3. Improve usability and consistency of cursor style between image-type
   *    `input` and others.
   */
  
  button,
  html input[type="button"], /* 1 */
  input[type="reset"],
  input[type="submit"] {
      -webkit-appearance: button; /* 2 */
      cursor: pointer; /* 3 */
  }
  
  /**
   * Re-set default cursor for disabled elements.
   */
  
  button[disabled],
  html input[disabled] {
      cursor: default;
  }
  
  /**
   * 1. Address box sizing set to `content-box` in IE 8/9/10.
   * 2. Remove excess padding in IE 8/9/10.
   */
  
  input[type="checkbox"],
  input[type="radio"] {
      box-sizing: border-box; /* 1 */
      padding: 0; /* 2 */
  }
  
  /**
   * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
   * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
   *    (include `-moz` to future-proof).
   */
  
  input[type="search"] {
      -webkit-appearance: textfield; /* 1 */
      -moz-box-sizing: content-box;
      -webkit-box-sizing: content-box; /* 2 */
      box-sizing: content-box;
  }
  
  /**
   * Remove inner padding and search cancel button in Safari 5 and Chrome
   * on OS X.
   */
  
  input[type="search"]::-webkit-search-cancel-button,
  input[type="search"]::-webkit-search-decoration {
      -webkit-appearance: none;
  }
  
  /**
   * Remove inner padding and border in Firefox 4+.
   */
  
  button::-moz-focus-inner,
  input::-moz-focus-inner {
      border: 0;
      padding: 0;
  }
  
  /**
   * 1. Remove default vertical scrollbar in IE 8/9.
   * 2. Improve readability and alignment in all browsers.
   */
  
  textarea {
      overflow: auto; /* 1 */
      vertical-align: top; /* 2 */
  }
  
  /* ==========================================================================
     Tables
     ========================================================================== */
  
  /**
   * Remove most spacing between table cells.
   */
  
  table {
      border-collapse: collapse;
      border-spacing: 0;
  }
  
  .go-top {
  position: fixed;
  bottom: 2em;
  right: 2em;
  text-decoration: none;
  background-color: #E0E0E0;
  font-size: 12px;
  padding: 1em;
  display: inline;
  }
  
  /* Github css */
  
  html,body{        margin: auto;
      padding-right: 1em;
      padding-left: 1em;
      max-width: 66em; color:black;}
  *:not('#mkdbuttons'){margin:0;padding:0}
  body{font:13.34px helvetica,arial,freesans,clean,sans-serif;-webkit-font-smoothing:subpixel-antialiased;line-height:1.4;padding:3px;background:#fff;border-radius:3px;-moz-border-radius:3px;-webkit-border-radius:3px}
  p{margin:1em 0}
  a{color:#4183c4;text-decoration:none}
  body{background-color:#fff;padding:30px;margin:15px;font-size:14px;line-height:1.6}
  body>*:first-child{margin-top:0!important}
  body>*:last-child{margin-bottom:0!important}
  @media screen{body{box-shadow:0 0 0 1px #cacaca,0 0 0 4px #eee}}
  h1,h2,h3,h4,h5,h6{margin:20px 0 10px;padding:0;font-weight:bold;-webkit-font-smoothing:subpixel-antialiased;cursor:text}
  h1{font-size:28px;color:#000}
  h2{font-size:24px;border-bottom:1px solid #ccc;color:#000}
  h3{font-size:18px;color:#333}
  h4{font-size:16px;color:#333}
  h5{font-size:14px;color:#333}
  h6{color:#777;font-size:14px}
  p,blockquote,table,pre{margin:15px 0}
  ul{padding-left:30px}ol{padding-left:30px}
  ol li ul:first-of-type{margin-top:0}
  hr{background:transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAEAQMAAACXytwAAAAABlBMVEUAAAAAAAClZ7nPAAAAAnRSTlMzAIL4qAgAAAAQSURBVAjXY3jAcIShh0EGAAu8Ak3MBNBbAAAAAElFTkSuQmCC) repeat-x 0 0;border:0 none;color:#ccc;height:4px;padding:0}
  body>h2:first-child{margin-top:0;padding-top:0}
  body>h1:first-child{margin-top:0;padding-top:0}
  body>h1:first-child+h2{margin-top:0;padding-top:0}
  body>h3:first-child,body>h4:first-child,body>h5:first-child,body>h6:first-child{margin-top:0;padding-top:0}
  a:first-child h1,a:first-child h2,a:first-child h3,a:first-child h4,a:first-child h5,a:first-child h6{margin-top:0;padding-top:0}
  h1+p,h2+p,h3+p,h4+p,h5+p,h6+p,ul li>:first-child,ol li>:first-child{margin-top:0}
  dl{padding:0}
  dl dt{font-size:14px;font-weight:bold;font-style:italic;padding:0;margin:15px 0 5px}
  dl dt:first-child{padding:0}dl dt>:first-child{margin-top:0}dl dt>:last-child{margin-bottom:0}
  dl dd{margin:0 0 15px;padding:0 15px}dl dd>:first-child{margin-top:0}
  dl dd>:last-child{margin-bottom:0}
  blockquote{border-left:4px solid #DDD;padding:0 15px;color:#777}
  blockquote>:first-child{margin-top:0}
  blockquote>:last-child{margin-bottom:0}
  table{border-collapse:collapse;border-spacing:0;font-size:100%;font:inherit}
  table th{font-weight:bold;border:1px solid #ccc;padding:6px 13px}
  table td{border:1px solid #ccc;padding:6px 13px}
  table tr{border-top:1px solid #ccc;background-color:#fff}
  table tr:nth-child(2n){background-color:#f8f8f8}
  img{max-width:100%}
  code,tt{margin:0 2px;padding:0 5px;white-space:nowrap;border:1px solid #eaeaea;background-color:#f8f8f8;border-radius:3px;font-family:Consolas,'Liberation Mono',Courier,monospace;font-size:12px;color:#333}
  pre>code{margin:0;padding:0;white-space:pre;border:0;background:transparent}
  .highlight pre{background-color:#f8f8f8;border:1px solid #ccc;font-size:13px;line-height:19px;overflow:auto;padding:6px 10px;border-radius:3px}
  pre{background-color:#f8f8f8;border:1px solid #ccc;font-size:13px;line-height:19px;overflow:auto;padding:6px 10px;border-radius:3px}
  pre code,pre tt{background-color:transparent;border:0}
  .poetry pre{font-family:Georgia,Garamond,serif!important;font-style:italic;font-size:110%!important;line-height:1.6em;display:block;margin-left:1em}
  .poetry pre code{font-family:Georgia,Garamond,serif!important;word-break:break-all;word-break:break-word;-webkit-hyphens:auto;-moz-hyphens:auto;hyphens:auto;white-space:pre-wrap}
  sup,sub,a.footnote{font-size:1.4ex;height:0;line-height:1;vertical-align:super;position:relative}
  sub{vertical-align:sub;top:-1px}
  
  @media print{
  	body{background:#fff}
  	img,pre,blockquote,table,figure{page-break-inside:avoid}
  	body{background:#fff;border:0}
  	code{background-color:#fff;color:#333!important;padding:0 .2em;border:1px solid #dedede}
  	pre{background:#fff}
  	pre code{background-color:white!important;overflow:visible}}
  @media screen{
  	body.inverted{color:#eee!important;border-color:#555;box-shadow:none}
  	.inverted body,.inverted hr .inverted p,.inverted td,.inverted li,.inverted h1,.inverted h2,.inverted h3,.inverted h4,.inverted h5,.inverted h6,.inverted th,.inverted .math,.inverted caption,.inverted dd,.inverted dt,.inverted blockquote{color:#eee!important;border-color:#555;box-shadow:none}
  	.inverted td,.inverted th{background:#333}
  	.inverted h2{border-color:#555}
  	.inverted hr{border-color:#777;border-width:1px!important}
  	::selection{background:rgba(157,193,200,0.5)}
  	h1::selection{background-color:rgba(45,156,208,0.3)}
  	h2::selection{background-color:rgba(90,182,224,0.3)}
  	h3::selection,h4::selection,h5::selection,h6::selection,li::selection,ol::selection{background-color:rgba(133,201,232,0.3)}
  	code::selection{background-color:rgba(0,0,0,0.7);color:#eee}
  	code span::selection{background-color:rgba(0,0,0,0.7)!important;color:#eee!important}
  	a::selection{background-color:rgba(255,230,102,0.2)}
  	.inverted a::selection{background-color:rgba(255,230,102,0.6)}
  	td::selection,th::selection,caption::selection{background-color:rgba(180,237,95,0.5)}
  	.inverted{background:#0b2531;background:#252a2a}
  	.inverted body{background:#252a2a}
  	.inverted a{color:#acd1d5}}
  
  .highlight .c{color:#998;font-style:italic}
  .highlight .err{color:#a61717;background-color:#e3d2d2}
  .highlight .k,.highlight .o{font-weight:bold}
  .highlight .cm{color:#998;font-style:italic}
  .highlight .cp{color:#999;font-weight:bold}
  .highlight .c1{color:#998;font-style:italic}
  .highlight .cs{color:#999;font-weight:bold;font-style:italic}
  .highlight .gd{color:#000;background-color:#fdd}
  .highlight .gd .x{color:#000;background-color:#faa}
  .highlight .ge{font-style:italic}
  .highlight .gr{color:#a00}
  .highlight .gh{color:#999}
  .highlight .gi{color:#000;background-color:#dfd}
  .highlight .gi .x{color:#000;background-color:#afa}
  .highlight .go{color:#888}
  .highlight .gp{color:#555}
  .highlight .gs{font-weight:bold}
  .highlight .gu{color:#800080;font-weight:bold}
  .highlight .gt{color:#a00}
  .highlight .kc,.highlight .kd,.highlight .kn,.highlight .kp,.highlight .kr{font-weight:bold}
  .highlight .kt{color:#458;font-weight:bold}
  .highlight .m{color:#099}
  .highlight .s{color:#d14}
  .highlight .na{color:#008080}
  .highlight .nb{color:#0086b3}
  .highlight .nc{color:#458;font-weight:bold}
  .highlight .no{color:#008080}
  .highlight .ni{color:#800080}
  .highlight .ne,.highlight .nf{color:#900;font-weight:bold}
  .highlight .nn{color:#555}
  .highlight .nt{color:#000080}
  .highlight .nv{color:#008080}
  .highlight .ow{font-weight:bold}
  .highlight .w{color:#bbb}
  .highlight .mf,.highlight .mh,.highlight .mi,.highlight .mo{color:#099}
  .highlight .sb,.highlight .sc,.highlight .sd,.highlight .s2,.highlight .se,.highlight .sh,.highlight .si,.highlight .sx{color:#d14}
  .highlight .sr{color:#009926}
  .highlight .s1{color:#d14}
  .highlight .ss{color:#990073}
  .highlight .bp{color:#999}
  .highlight .vc,.highlight .vg,.highlight .vi{color:#008080}
  .highlight .il{color:#099}
  .highlight .gc{color:#999;background-color:#eaf2f5}
  .type-csharp .highlight .k,.type-csharp .highlight .kt{color:#00F}
  .type-csharp .highlight .nf{color:#000;font-weight:normal}
  .type-csharp .highlight .nc{color:#2b91af}
  .type-csharp .highlight .nn{color:#000}
  .type-csharp .highlight .s,.type-csharp .highlight .sc{color:#a31515}
  
  /* Sphinx3 specific hacks here */
  /*
  code span.kw { color: #007020; font-weight: bold; } // Keyword
  code span.dt { color: #902000; } // DataType
  code span.dv { color: #40a070; } // DecVal
  code span.st { color: #4070a0; } // String
  */
  
  </style>
</head>
<body>
<header>
<h1 class="title">Sphinx 3 manual</h1>
</header>
<nav id="TOC">
<ul>
<li><a href="#sphinx-3">Sphinx 3</a><ul>
<li><a href="#wip-notice">WIP notice</a></li>
<li><a href="#features-overview">Features overview</a></li>
<li><a href="#features-cheat-sheet">Features cheat sheet</a></li>
<li><a href="#getting-started">Getting started</a><ul>
<li><a href="#getting-started-on-linux-and-macos">Getting started on Linux (and MacOS)</a></li>
<li><a href="#getting-started-on-windows">Getting started on Windows</a></li>
<li><a href="#running-queries-via-mysql-shell">Running queries via MySQL shell</a></li>
<li><a href="#running-queries-from-php-python-etc">Running queries from PHP, Python, etc</a></li>
<li><a href="#running-queries-via-http">Running queries via HTTP</a></li>
<li><a href="#installing-indexer-sql-drivers-on-linux">Installing <code>indexer</code> SQL drivers on Linux</a></li>
</ul></li>
<li><a href="#main-concepts">Main concepts</a><ul>
<li><a href="#indexes">Indexes</a></li>
<li><a href="#documents">Documents</a></li>
<li><a href="#fields">Fields</a></li>
<li><a href="#attributes">Attributes</a></li>
</ul></li>
<li><a href="#using-docstore">Using DocStore</a></li>
<li><a href="#using-attribute-indexes">Using attribute indexes</a></li>
<li><a href="#using-k-batches">Using k-batches</a></li>
<li><a href="#doing-bulk-data-loads">Doing bulk data loads</a></li>
<li><a href="#using-json">Using JSON</a></li>
<li><a href="#indexing-csv-and-tsv-files">Indexing: CSV and TSV files</a></li>
<li><a href="#indexing-special-chars-blended-tokens-and-mixed-codes">Indexing: special chars, blended tokens, and mixed codes</a><ul>
<li><a href="#blended-tokens-with-special-characters">Blended tokens (with special characters)</a></li>
<li><a href="#mixed-codes-with-letters-and-digits">Mixed codes (with letters and digits)</a></li>
<li><a href="#blending-modes">Blending modes</a></li>
<li><a href="#searching-vs-blended-tokens-and-mixed-codes">Searching vs blended tokens and mixed codes</a></li>
</ul></li>
<li><a href="#ranking-idf-magics">Ranking: IDF magics</a></li>
<li><a href="#ranking-picking-fields-with-rank_fields">Ranking: picking fields with <code>rank_fields</code></a></li>
<li><a href="#changes-in-3.x">Changes in 3.x</a><ul>
<li><a href="#version-3.1.1-17-oct-2018">Version 3.1.1, 17 oct 2018</a></li>
<li><a href="#version-3.0.3-30-mar-2018">Version 3.0.3, 30 mar 2018</a></li>
<li><a href="#version-3.0.2-25-feb-2018">Version 3.0.2, 25 feb 2018</a></li>
<li><a href="#version-3.0.1-18-dec-2017">Version 3.0.1, 18 dec 2017</a></li>
</ul></li>
<li><a href="#changes-since-2.x">Changes since 2.x</a></li>
<li><a href="#copyrights">Copyrights</a></li>
</ul></li>
</ul>
</nav>
<h1 id="sphinx-3">Sphinx 3</h1>
<p>Sphinx is a free, dual-licensed search server. Sphinx is written in C++, and focuses on query performance and search relevance.</p>
<p>The primary client API is currently SphinxQL, a dialect of SQL. Almost any MySQL connector should work. Additionally, basic HTTP/JSON API and native APIs for a number of languages (PHP, Python, Ruby, C, Java) are provided.</p>
<p>This document is an effort to build a better documentation for Sphinx 3 and up. Think of it as a book or a tutorial which you would actually <em>read</em>; think of the previous “reference manual” as of a “dictionary” where you look up specific syntax features. The two might (and should) eventually converge.</p>
<h2 id="wip-notice">WIP notice</h2>
<p>Sphinx 3 is currently (early 2018) still under active refactoring, so a lot of things might and <em>will</em> change in the future.</p>
<p>I will try to mark those as WIP (Work In Progress), but be patient if things in your current build aren’t as documented here. That simply means that the behavior already changed but the docs just did not catch up. Do submit a bug report!</p>
<h2 id="features-overview">Features overview</h2>
<p>Top level picture, what does Sphinx 3 offer?</p>
<ul>
<li>SQL, HTTP/JSON, and custom native SphinxAPI access APIs</li>
<li>NRT (Near Real Time) and offline batch indexing</li>
<li>Full-text and non-text (parameter) searching</li>
<li>Relevance ranking, from basic formulas to ML models</li>
<li>Federated results from multiple servers</li>
<li>Decent performance</li>
</ul>
<p>Other things that seem worth mentioning (this list is probably incomplete at all times, and definitely in random order):</p>
<ul>
<li>Morphology and text-processing tools
<ul>
<li>Fully flexible tokenization (see <code>charset_table</code> and <code>exceptions</code>)</li>
<li>Proper morphology (lemmatizer) for English, Russian, and German (see <code>morphology</code>)</li>
<li>Basic morphology (stemmer) for many other languages</li>
<li>User-specified wordforms, <code>core 2 duo =&gt; c2d</code></li>
</ul></li>
<li>Native JSON support</li>
<li>Geosearch support</li>
<li>Fast expressions engine</li>
<li>Query suggestions</li>
<li>Snippets builder</li>
<li>…</li>
</ul>
<p>And, of course, there is always stuff that we know we currently lack!</p>
<ul>
<li>Index replication</li>
<li>…</li>
</ul>
<h2 id="features-cheat-sheet">Features cheat sheet</h2>
<p>This section is supposed to provide a bit more detail on all the available features; to cover them more or less fully; and give you some further pointers into the specific reference sections (on the related config directives and SphinxQL statements).</p>
<ul>
<li>Full-text search queries, see <code>SELECT ... WHERE MATCH('this')</code> SphinxQL statement
<ul>
<li>Boolean matching operators (implicit AND, explicit OR, NOT, and brackets), as in <code>(one two) | (three !four)</code></li>
<li>Boolean matching optimizations, see <code>OPTION boolean_simplify=1</code> in <code>SELECT</code> statement</li>
<li>Advanced text matching operators
<ul>
<li>Field restrictions, <code>@title hello world</code> or <code>@!title hello</code> or <code>@(title,body) any of the two</code> etc</li>
<li>In-field position restrictions, <code>@title[50] hello</code></li>
<li>MAYBE operator for optional keyword matching, <code>cat MAYBE dog</code></li>
<li>phrase matching, <code>&quot;roses are red&quot;</code></li>
<li>quorum matching, <code>&quot;pick any 3 keywords out of this entire set&quot;/3</code></li>
<li>proximity matching, <code>&quot;within 10 positions all terms in yoda order&quot;~10</code> or <code>hello NEAR/3 world NEAR/4 &quot;my test&quot;</code></li>
<li>strict order matching, <code>(bag of words) &lt;&lt; &quot;exact phrase&quot; &lt;&lt; this|that</code></li>
<li>sentence matching, <code>all SENTENCE words SENTENCE &quot;in one sentence&quot;</code></li>
<li>paragraph matching, <code>&quot;Bill Gates&quot; PARAGRAPH &quot;Steve Jobs&quot;</code></li>
<li>zone and zone-span matching, <code>ZONE:(h3,h4) in any of these title tags</code> and <code>ZONESPAN:(h2) only in a single instance</code></li>
</ul></li>
<li>Keyword modifiers (that can usually be used within operators)
<ul>
<li>exact (pre-morphology) form modifier, <code>raining =cats and =dogs</code></li>
<li>field-start and field-end modifiers, <code>^hello world$</code></li>
<li>IDF (ranking) boost, <code>boosted^1.234</code></li>
</ul></li>
<li>Substring and wildcard searches
<ul>
<li>see <code>min_prefix_len</code> and <code>min_infix_len</code> directives</li>
<li>use <code>th?se three keyword% wild*cards *verywher*</code> (<code>?</code> = 1 char exactly; <code>%</code> = 0 or 1 char; <code>*</code> = 0 or more chars)</li>
</ul></li>
</ul></li>
<li>…</li>
</ul>
<p>TODO: describe more, add links!</p>
<h2 id="getting-started">Getting started</h2>
<p>That should now be rather simple. No magic installation required! On any platform, the <em>sufficient</em> thing to do is:</p>
<ol type="1">
<li>Get the binaries.</li>
<li>Run <code>searchd</code></li>
<li>Create indexes.</li>
<li>Run queries.</li>
</ol>
<p>Or alternatively, you can ETL your data offline, using the <code>indexer</code> tool:</p>
<ol type="1">
<li>Get the binaries.</li>
<li>Create <code>sphinx.conf</code></li>
<li>Run <code>indexer --all</code> once, to initially create the indexes.</li>
<li>Run <code>searchd</code></li>
<li>Run queries.</li>
<li>Run <code>indexer --all --rotate</code> regularly, to update the indexes.</li>
</ol>
<p>Note that instead of inserting the data into indexes online, the <code>indexer</code> tool instead creates a shadow copy of the specified index(es) offline, and then sends a signal to <code>searchd</code> to pick up that copy. So you should <em>never</em> get a partially populated index with <code>indexer</code>; it’s always all-or-nothing.</p>
<h3 id="getting-started-on-linux-and-macos">Getting started on Linux (and MacOS)</h3>
<p>Versions and file names <em>will</em> vary, and you most likely <em>will</em> want to configure Sphinx at least a little, but for an immediate quickstart:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><div class="sourceLine" id="1" href="#1" data-line-number="1">$ <span class="fu">wget</span> -q http://sphinxsearch.com/files/sphinx-3.0.2-2592786-linux-amd64.tar.gz</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2">$ <span class="fu">tar</span> zxf sphinx-3.0.2-2592786-linux-amd64.tar.gz</div>
<div class="sourceLine" id="3" href="#3" data-line-number="3">$ <span class="bu">cd</span> sphinx-3.0.2-2592786-linux-amd64/bin</div>
<div class="sourceLine" id="4" href="#4" data-line-number="4">$ <span class="ex">./searchd</span></div>
<div class="sourceLine" id="5" href="#5" data-line-number="5"><span class="ex">Sphinx</span> 3.0.2 (commit 2592786)</div>
<div class="sourceLine" id="6" href="#6" data-line-number="6"><span class="ex">Copyright</span> (c) <span class="ex">2001-2018</span>, Andrew Aksyonoff</div>
<div class="sourceLine" id="7" href="#7" data-line-number="7"><span class="ex">Copyright</span> (c) <span class="ex">2008-2016</span>, Sphinx Technologies Inc (http://sphinxsearch.com)</div>
<div class="sourceLine" id="8" href="#8" data-line-number="8"></div>
<div class="sourceLine" id="9" href="#9" data-line-number="9"><span class="ex">listening</span> on all interfaces, port=9312</div>
<div class="sourceLine" id="10" href="#10" data-line-number="10"><span class="ex">listening</span> on all interfaces, port=9306</div>
<div class="sourceLine" id="11" href="#11" data-line-number="11"><span class="ex">WARNING</span>: No extra index definitions found in data folder</div>
<div class="sourceLine" id="12" href="#12" data-line-number="12">$</div></code></pre>
<p>That’s it; the daemon should now be running and accepting connections on port 9306. And you can connect to it using MySQL CLI (see below for more details, or just try <code>mysql -P9306</code> right away).</p>
<h3 id="getting-started-on-windows">Getting started on Windows</h3>
<p>Pretty much the same story, except that on Windows <code>searchd</code> will not automatically go into background:</p>
<pre><code>C:\Sphinx\&gt;searchd.exe
Sphinx 3.0-dev (c3c241f)
...
accepting connections
prereaded 0 indexes in 0.000 sec</code></pre>
<p>This is alright. Do not kill it. Just switch to a separate session and start querying.</p>
<h3 id="running-queries-via-mysql-shell">Running queries via MySQL shell</h3>
<p>Run the MySQL CLI and point it to a port 9306. For example on Windows:</p>
<pre><code>C:\&gt;mysql -h127.0.0.1 -P9306
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 1
Server version: 3.0-dev (c3c241f)
...</code></pre>
<p>I have intentionally used <code>127.0.0.1</code> in this example for two reasons (both caused by MySQL CLI quirks, not Sphinx):</p>
<ul>
<li>sometimes, an IP address is required to use the <code>-P9306</code> switch, not <code>localhost</code></li>
<li>sometimes, <code>localhost</code> works but causes a connection delay</li>
</ul>
<p>But in the simplest case even just <code>mysql -P9306</code> should work fine.</p>
<p>And from there, just run SphinxQL queries:</p>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1">mysql&gt; <span class="kw">CREATE</span> <span class="kw">TABLE</span> test (gid <span class="dt">integer</span>, title field stored,</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2">    -&gt; content field stored);</div>
<div class="sourceLine" id="3" href="#3" data-line-number="3"><span class="kw">Query</span> OK, <span class="dv">0</span> <span class="kw">rows</span> affected (<span class="fl">0.00</span> sec)</div>
<div class="sourceLine" id="4" href="#4" data-line-number="4"></div>
<div class="sourceLine" id="5" href="#5" data-line-number="5">mysql&gt; <span class="kw">INSERT</span> <span class="kw">INTO</span> test (<span class="kw">id</span>, title) <span class="kw">VALUES</span> (<span class="dv">123</span>, <span class="st">&#39;hello world&#39;</span>);</div>
<div class="sourceLine" id="6" href="#6" data-line-number="6"><span class="kw">Query</span> OK, <span class="dv">1</span> <span class="kw">row</span> affected (<span class="fl">0.00</span> sec)</div>
<div class="sourceLine" id="7" href="#7" data-line-number="7"></div>
<div class="sourceLine" id="8" href="#8" data-line-number="8">mysql&gt; <span class="kw">INSERT</span> <span class="kw">INTO</span> test (<span class="kw">id</span>, gid, content) <span class="kw">VALUES</span> (<span class="dv">234</span>, <span class="dv">345</span>, <span class="st">&#39;empty title&#39;</span>);</div>
<div class="sourceLine" id="9" href="#9" data-line-number="9"><span class="kw">Query</span> OK, <span class="dv">1</span> <span class="kw">row</span> affected (<span class="fl">0.00</span> sec)</div>
<div class="sourceLine" id="10" href="#10" data-line-number="10"></div>
<div class="sourceLine" id="11" href="#11" data-line-number="11">mysql&gt; <span class="kw">SELECT</span> * <span class="kw">FROM</span> test;</div>
<div class="sourceLine" id="12" href="#12" data-line-number="12">+<span class="co">------+------+-------------+-------------+</span></div>
<div class="sourceLine" id="13" href="#13" data-line-number="13">| <span class="kw">id</span>   | gid  | title       | content     |</div>
<div class="sourceLine" id="14" href="#14" data-line-number="14">+<span class="co">------+------+-------------+-------------+</span></div>
<div class="sourceLine" id="15" href="#15" data-line-number="15">|  <span class="dv">123</span> |    <span class="dv">0</span> | hello world |             |</div>
<div class="sourceLine" id="16" href="#16" data-line-number="16">|  <span class="dv">234</span> |  <span class="dv">345</span> |             | <span class="kw">empty</span> title |</div>
<div class="sourceLine" id="17" href="#17" data-line-number="17">+<span class="co">------+------+-------------+-------------+</span></div>
<div class="sourceLine" id="18" href="#18" data-line-number="18"><span class="dv">2</span> <span class="kw">rows</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</div>
<div class="sourceLine" id="19" href="#19" data-line-number="19"></div>
<div class="sourceLine" id="20" href="#20" data-line-number="20">mysql&gt; <span class="kw">SELECT</span> * <span class="kw">FROM</span> test <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>);</div>
<div class="sourceLine" id="21" href="#21" data-line-number="21">+<span class="co">------+------+-------------+---------+</span></div>
<div class="sourceLine" id="22" href="#22" data-line-number="22">| <span class="kw">id</span>   | gid  | title       | content |</div>
<div class="sourceLine" id="23" href="#23" data-line-number="23">+<span class="co">------+------+-------------+---------+</span></div>
<div class="sourceLine" id="24" href="#24" data-line-number="24">|  <span class="dv">123</span> |    <span class="dv">0</span> | hello world |         |</div>
<div class="sourceLine" id="25" href="#25" data-line-number="25">+<span class="co">------+------+-------------+---------+</span></div>
<div class="sourceLine" id="26" href="#26" data-line-number="26"><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</div>
<div class="sourceLine" id="27" href="#27" data-line-number="27"></div>
<div class="sourceLine" id="28" href="#28" data-line-number="28">mysql&gt; <span class="kw">SELECT</span> * <span class="kw">FROM</span> test <span class="kw">WHERE</span> MATCH(<span class="st">&#39;@content hello&#39;</span>);</div>
<div class="sourceLine" id="29" href="#29" data-line-number="29"><span class="kw">Empty</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</div></code></pre>
<p>SphinxQL is our own SQL dialect. More details on the supported statements are currently available in 2.x docs, see <a href="sphinx2.html#sphinxql-reference">SphinxQL Reference</a></p>
<h3 id="running-queries-from-php-python-etc">Running queries from PHP, Python, etc</h3>
<pre class="sourceCode php"><code class="sourceCode php"><div class="sourceLine" id="1" href="#1" data-line-number="1"><span class="kw">&lt;?php</span></div>
<div class="sourceLine" id="2" href="#2" data-line-number="2"></div>
<div class="sourceLine" id="3" href="#3" data-line-number="3"><span class="kw">$conn</span> = <span class="fu">mysqli_connect</span><span class="ot">(</span><span class="st">&quot;127.0.0.1:9306&quot;</span><span class="ot">,</span> <span class="st">&quot;&quot;</span><span class="ot">,</span> <span class="st">&quot;&quot;</span><span class="ot">,</span> <span class="st">&quot;&quot;</span><span class="ot">);</span></div>
<div class="sourceLine" id="4" href="#4" data-line-number="4"><span class="kw">if</span> <span class="ot">(</span><span class="fu">mysqli_connect_errno</span><span class="ot">())</span></div>
<div class="sourceLine" id="5" href="#5" data-line-number="5">    <span class="kw">die</span><span class="ot">(</span><span class="st">&quot;failed to connect to Sphinx: &quot;</span> . <span class="fu">mysqli_connect_error</span><span class="ot">());</span></div>
<div class="sourceLine" id="6" href="#6" data-line-number="6"></div>
<div class="sourceLine" id="7" href="#7" data-line-number="7"><span class="kw">$res</span> = <span class="fu">mysqli_query</span><span class="ot">(</span><span class="kw">$conn</span><span class="ot">,</span> <span class="st">&quot;SHOW VARIABLES&quot;</span><span class="ot">);</span></div>
<div class="sourceLine" id="8" href="#8" data-line-number="8"><span class="kw">while</span> <span class="ot">(</span><span class="kw">$row</span> = <span class="fu">mysqli_fetch_row</span><span class="ot">(</span><span class="kw">$res</span><span class="ot">))</span></div>
<div class="sourceLine" id="9" href="#9" data-line-number="9">    <span class="kw">print</span> <span class="st">&quot;</span><span class="kw">$row[0]</span><span class="st">: </span><span class="kw">$row[1]\n</span><span class="st">&quot;</span><span class="ot">;</span></div></code></pre>
<p>TODO: examples</p>
<h3 id="running-queries-via-http">Running queries via HTTP</h3>
<p>TODO: examples</p>
<h3 id="installing-indexer-sql-drivers-on-linux">Installing <code>indexer</code> SQL drivers on Linux</h3>
<p>This only affects <code>indexer</code> ETL tool only. If you never bulk load data from SQL sources using it (of course CSV and XML sources are still fine), you can safely skip this section. (And on Windows all the drivers come with the package.)</p>
<p>Depending on your OS, the required package names may vary. Here are some current (as of Mar 2018) package names for Ubuntu and CentOS:</p>
<pre class="sourceCode bash"><code class="sourceCode bash"><div class="sourceLine" id="1" href="#1" data-line-number="1"><span class="ex">ubuntu</span>$ apt-get install libmysqlclient-dev libpq-dev unixodbc-dev</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2"><span class="ex">ubuntu</span>$ apt-get install libmariadb-client-lgpl-dev-compat</div>
<div class="sourceLine" id="3" href="#3" data-line-number="3"></div>
<div class="sourceLine" id="4" href="#4" data-line-number="4"><span class="ex">centos</span>$ yum install mariadb-devel postgresql-devel unixODBC-devel</div></code></pre>
<p>Why might these be needed, and how they work?</p>
<p><code>indexer</code> natively supports MySQL (or MariaDB), PostgreSQL, and UnixODBC drivers. Meaning it can natively connect to those databases, run SQL queries, extract results, and create full-text indexes from that. Binaries now always come with that <em>support</em> enabled.</p>
<p>However, you still need to have a specific driver <em>library</em> installed on your system, so that <code>indexer</code> could dynamically load it, and access the database. Depending on the specific database and OS you use, the package names might be different, but here go a few common pointers.</p>
<p>The driver libraries are loaded by name. The following names are attempted:</p>
<ul>
<li>MySQL: <code>libmysqlclient.so</code> or <code>libmariadb.so</code></li>
<li>PostgreSQL: <code>libpq.so</code></li>
<li>ODBC: <code>libodbc.so</code></li>
</ul>
<p>To support MacOS, <code>.dylib</code> extension (in addition to <code>.so</code>) is also tried.</p>
<h2 id="main-concepts">Main concepts</h2>
<p>Alas, many projects tend to reinvent their own dictionary, and Sphinx is no exception. Sometimes that probably creates confusion for no apparent reason. For one, what SQL guys call “tables” (or even “relations” if they are old enough to remember Edgar Codd), and MongoDB guys call “collections”, we the text search guys tend to call “indexes”, and not really out of mischief and malice either, but just because for us, those things <em>are</em> primarily FT (full-text) indexes. Thankfully, most of the concepts are close enough, so our personal little Sphinx dictionary is tiny. Let’s see.</p>
<p>Short cheat-sheet!</p>
<table>
<thead>
<tr class="header">
<th>Sphinx</th>
<th>Closest SQL equivalent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Index</td>
<td>Table</td>
</tr>
<tr class="even">
<td>Document</td>
<td>Row</td>
</tr>
<tr class="odd">
<td>Field or attribute</td>
<td>Column and/or a FULLTEXT index</td>
</tr>
<tr class="even">
<td>Indexed field</td>
<td><em>Just</em> a FULLTEXT index on a text column</td>
</tr>
<tr class="odd">
<td>Stored field</td>
<td>Text column <em>and</em> a FULLTEXT index on it</td>
</tr>
<tr class="even">
<td>Attribute</td>
<td>Column</td>
</tr>
<tr class="odd">
<td>MVA</td>
<td>Column with an INT_SET type</td>
</tr>
<tr class="even">
<td>JSON attribute</td>
<td>Column with a JSON type</td>
</tr>
<tr class="odd">
<td>Attribute index</td>
<td>Index</td>
</tr>
<tr class="even">
<td>Document ID, docid</td>
<td>Column called “id”, with a BIGINT type</td>
</tr>
<tr class="odd">
<td>Row ID, rowid</td>
<td>Internal Sphinx row number</td>
</tr>
</tbody>
</table>
<p>And now for a little more elaborate explanation.</p>
<h3 id="indexes">Indexes</h3>
<p>Sphinx indexes are semi-structured collections of documents. They may seem closer to SQL tables than to Mongo collections, but in their core, they really are neither. The primary, foundational data structure here is a <em>full-text index</em>. It is a special structure that lets us respond very quickly to a query like “give me the (internal) identifiers of all the documents that mention This or That keyword”. And everything else (any extra attributes, or document storage, or even the SQL or HTTP querying dialects, and so on) that Sphinx provides is essentially some kind of an addition on top of that base data structure. Well, hence the “index” name.</p>
<p>Schema-wise, Sphinx indexes try to combine the best of schemaful and schemaless worlds. For “columns” where you know the type upfront, you can use the statically typed attributes, and get the absolute efficiency. For more dynamic data, you can put it all into a JSON attribute, and still get quite decent performance.</p>
<p>So in a sense, Sphinx indexes == SQL tables, except (a) full-text searches are fast and come with a lot of full-text-search specific tweaking options; (b) JSON “columns” (attributes) are quite natively supported, so you can go schemaless; and (c) for full-text indexed fields, you can choose to store <em>just</em> the full-text index and ditch the original values.</p>
<h3 id="documents">Documents</h3>
<p>Documents are essentially just a list of named text fields, and arbitrary-typed attributes. Quite similar to SQL rows; almost indistiguishable, actually.</p>
<p>As of 3.0.1, Sphinx still requires a unique <code>id</code> attribute, and implicitly injects an <code>id BIGINT</code> column into indexes (as you probably noticed in the <a href="#getting-started">Getting started</a> section). We still use those docids to identify specific rows in <code>DELETE</code> and other statements. However, unlike in 2.x, we no longer use docids to identify documents internally. Thus, zero and negative docids are already allowed.</p>
<h3 id="fields">Fields</h3>
<p>Fields are the texts that Sphinx indexes and makes keyword-searchable. They always are <em>indexed</em>, as in full-text indexed. Their original, unindexed contents can also be <em>stored</em> into the index for later retrieval. By default, they are not, and Sphinx is going to return attributes only, and <em>not</em> the contents. However, if you explicitly mark them as stored (either with a <code>stored</code> flag in <code>CREATE TABLE</code> or in the ETL config file using <code>stored_fields</code> directive), you can also fetch the fields back:</p>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1">mysql&gt; <span class="kw">CREATE</span> <span class="kw">TABLE</span> test1 (title field);</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2">mysql&gt; <span class="kw">INSERT</span> <span class="kw">INTO</span> test1 <span class="kw">VALUES</span> (<span class="dv">123</span>, <span class="st">&#39;hello&#39;</span>);</div>
<div class="sourceLine" id="3" href="#3" data-line-number="3">mysql&gt; <span class="kw">SELECT</span> * <span class="kw">FROM</span> test1 <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>);</div>
<div class="sourceLine" id="4" href="#4" data-line-number="4">+<span class="co">------+</span></div>
<div class="sourceLine" id="5" href="#5" data-line-number="5">| <span class="kw">id</span>   |</div>
<div class="sourceLine" id="6" href="#6" data-line-number="6">+<span class="co">------+</span></div>
<div class="sourceLine" id="7" href="#7" data-line-number="7">|  <span class="dv">123</span> |</div>
<div class="sourceLine" id="8" href="#8" data-line-number="8">+<span class="co">------+</span></div>
<div class="sourceLine" id="9" href="#9" data-line-number="9"><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</div>
<div class="sourceLine" id="10" href="#10" data-line-number="10"></div>
<div class="sourceLine" id="11" href="#11" data-line-number="11">mysql&gt; <span class="kw">CREATE</span> <span class="kw">TABLE</span> test2 (title field stored);</div>
<div class="sourceLine" id="12" href="#12" data-line-number="12">mysql&gt; <span class="kw">INSERT</span> <span class="kw">INTO</span> test2 <span class="kw">VALUES</span> (<span class="dv">123</span>, <span class="st">&#39;hello&#39;</span>);</div>
<div class="sourceLine" id="13" href="#13" data-line-number="13">mysql&gt; <span class="kw">SELECT</span> * <span class="kw">FROM</span> test2 <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>);</div>
<div class="sourceLine" id="14" href="#14" data-line-number="14">+<span class="co">------+-------+</span></div>
<div class="sourceLine" id="15" href="#15" data-line-number="15">| <span class="kw">id</span>   | title |</div>
<div class="sourceLine" id="16" href="#16" data-line-number="16">+<span class="co">------+-------+</span></div>
<div class="sourceLine" id="17" href="#17" data-line-number="17">|  <span class="dv">123</span> | hello |</div>
<div class="sourceLine" id="18" href="#18" data-line-number="18">+<span class="co">------+-------+</span></div>
<div class="sourceLine" id="19" href="#19" data-line-number="19"><span class="dv">1</span> <span class="kw">row</span> <span class="kw">in</span> <span class="kw">set</span> (<span class="fl">0.00</span> sec)</div></code></pre>
<p>Stored fields contents are stored in a special index component called document storage, or DocStore for short.</p>
<h3 id="attributes">Attributes</h3>
<p>Sphinx supports the following attribute types:</p>
<ul>
<li>INTEGER, unsigned 32-bit integer</li>
<li>BIGINT, signed 64-bit integer</li>
<li>FLOAT, 32-bit (single precision) floating point</li>
<li>BOOL, 1-bit boolean</li>
<li>STRING, a text string</li>
<li>JSON, a JSON document</li>
<li>MVA, an order-insensitive set of unique INTEGERs</li>
<li>MVA64, an order-insensitive set of unique BIGINTs</li>
</ul>
<p>All of these should be pretty straightforward. However, there are a couple Sphinx specific JSON performance tricks worth mentioning:</p>
<ul>
<li>All scalar values (integers, floats, doubles) are converted and internally stored natively.</li>
<li>All scalar value <em>arrays</em> are detected and also internally stored natively.</li>
<li>You can use <code>123.45f</code> syntax extension to mark 32-bit floats (by default all floating point values in JSON are 64-bit doubles).</li>
</ul>
<p>For example, when the following document is stored into a JSON column in Sphinx:</p>
<pre class="sourceCode json"><code class="sourceCode json"><div class="sourceLine" id="1" href="#1" data-line-number="1"><span class="fu">{</span><span class="dt">&quot;title&quot;</span><span class="fu">:</span><span class="st">&quot;test&quot;</span><span class="fu">,</span> <span class="dt">&quot;year&quot;</span><span class="fu">:</span><span class="dv">2017</span><span class="fu">,</span> <span class="dt">&quot;tags&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="dv">13</span><span class="ot">,</span><span class="dv">8</span><span class="ot">,</span><span class="dv">5</span><span class="ot">,</span><span class="dv">1</span><span class="ot">,</span><span class="dv">2</span><span class="ot">,</span><span class="dv">3</span><span class="ot">]</span><span class="fu">}</span></div></code></pre>
<p>Sphinx detects that the “tags” array consists of integers only, and stores the array data using 24 bytes exactly, using just 4 bytes per each of the 6 values. Of course, there still are the overheads of storing the JSON keys, and the general document structure, so the <em>entire</em> document will take more than that. Still, when it comes to storing bulk data into Sphinx index for later use, just provide a consistently typed JSON array, and that data will be stored - and processed! - with maximum efficiency.</p>
<p>Attributes are supposed to fit into RAM, and Sphinx is optimized towards that case. Ideally, of course, all your index data should fit into RAM, while being backed by a fast enough SSD for persistence.</p>
<p>Now, there are <em>fixed-width</em> and <em>variable-width</em> attributes among the supported types. Naturally, scalars like INTEGER and FLOAT will always occupy exactly 4 bytes each, while STRING and JSON types can be as short as, well, empty; or as long as several megabytes. How does that work internally? Or in other words, why don’t I just save everything as JSON?</p>
<p>The answer is performance. Internally, Sphinx has two separate storages for those row parts. Fixed-width attributes, including hidden system ones, are essentially stored in big static NxM matrix, where N is the number of rows, and M is the number of fixed-width attributes. Any accesses to those are very quick. All the variable-width attributes for a single row are grouped together, and stored in a separate storage. A single offset into that second storage (or “vrow” storage, short for “variable-width row part” storage) is stored as hidden fixed-width attribute. Thus, as you see, accessing a string or a JSON or an MVA value, let alone a JSON key, is somewhat more complicated. For example, to access that <code>year</code> JSON key from the example just above, Sphinx would need to:</p>
<ul>
<li>read <code>vrow_offset</code> from a hidden integer attribute</li>
<li>access the vrow part using that offset</li>
<li>decode the vrow, and find the needed JSON attribute start</li>
<li>decode the JSON, and find the <code>year</code> key start</li>
<li>check the key type, just in case it needs conversion to integer</li>
<li>finally, read the <code>year</code> value</li>
</ul>
<p>Of course, optimizations are done on every step here, but still, if you access a <em>lot</em> of those values (for sorting or filtering the query results), there will be a performance impact. Also, the deeper the key is buried into that JSON, the worse. For example, using a tiny test with 1,000,000 rows and just 4 integer attributes plus exactly the same 4 values stored in a JSON, computing a sum yields the following:</p>
<table>
<thead>
<tr class="header">
<th>Attribute</th>
<th>Time</th>
<th>Slowdown</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Any INT</td>
<td>0.032 sec</td>
<td>-</td>
</tr>
<tr class="even">
<td>1st JSON key</td>
<td>0.045 sec</td>
<td>1.4x</td>
</tr>
<tr class="odd">
<td>2nd JSON key</td>
<td>0.052 sec</td>
<td>1.6x</td>
</tr>
<tr class="even">
<td>3rd JSON key</td>
<td>0.059 sec</td>
<td>1.8x</td>
</tr>
<tr class="odd">
<td>4th JSON key</td>
<td>0.065 sec</td>
<td>2.0x</td>
</tr>
</tbody>
</table>
<p>And with more attributes it would eventually slowdown even worse than 2x times, especially if we also throw in more complicated attributes, like strings or nested objects.</p>
<p>So bottom line, why not JSON everything? As long as your queries only touch a handful of rows each, that is fine, actually! However, if you have a <em>lot</em> of data, you should try to identify some of the “busiest” columns for your queries, and store them as “regular” typed columns, that somewhat improves performance.</p>
<h2 id="using-docstore">Using DocStore</h2>
<p>Storing fields into your indexes is easy, just list those fields in a <code>stored_fields</code> directive and you’re all set:</p>
<pre><code>index mytest
{
    type = rt
    path = data/mytest

    rt_field = title
    rt_field = content
    stored_fields = title, content
    # hl_fields = title, content

    rt_attr_uint = gid
}</code></pre>
<p>Let’s check how that worked:</p>
<pre><code>mysql&gt; desc mytest;
+---------+--------+-----------------+------+
| Field   | Type   | Properties      | Key  |
+---------+--------+-----------------+------+
| id      | bigint |                 |      |
| title   | field  | indexed, stored |      |
| content | field  | indexed, stored |      |
| gid     | uint   |                 |      |
+---------+--------+-----------------+------+
4 rows in set (0.00 sec)

mysql&gt; insert into mytest (id, title) values (123, &#39;hello world&#39;);
Query OK, 1 row affected (0.00 sec)

mysql&gt; select * from mytest where match(&#39;hello&#39;);
+------+------+-------------+---------+
| id   | gid  | title       | content |
+------+------+-------------+---------+
|  123 |    0 | hello world |         |
+------+------+-------------+---------+
1 row in set (0.00 sec)</code></pre>
<p>Yay, original document contents! Not a huge step generally, not for a database anyway; but a nice improvement for Sphinx which was initially designed “for searching only” (oh, the mistakes of youth). And DocStore can do more than that, namely:</p>
<ul>
<li>store indexed fields, <code>store_fields</code> directive</li>
<li>store unindexed fields, <code>stored_only_fields</code> directive</li>
<li>store precomputed data to speedup snippets, <code>hl_fields</code> directive</li>
<li>be fine-tuned a little, using <code>docstore_type</code>, <code>docstore_comp</code>, and <code>docstore_block</code> directives</li>
</ul>
<p>So DocStore can effectively replace the existing <code>rt_field_string</code> directive. What are the differences, and when to use each?</p>
<p><code>rt_field_string</code> creates an <em>attribute</em>, uncompressed, and stored in RAM. Attributes are supposed to be small, and suitable for filtering (WHERE), sorting (ORDER BY), and other operations like that, by the millions. So if you really need to run queries like … WHERE title=‘abc’, or in case you want to update those strings on the fly, you will still need attributes.</p>
<p>But complete original document contents are rather rarely accessed in <em>that</em> way! Instead, you usually need just a handful of those, in the order of 10s to 100s, to have them displayed in the final search results, and/or create snippets. DocStore is designed exactly for that. It compresses all the data it receives (by default), and tries to keep most of the resulting “archive” on disk, only fetching a few documents at a time, in the very end.</p>
<p>Snippets become pretty interesting with DocStore. You can generate snippets from either specific stored fields, or the entire document, or a subdocument, respectively:</p>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1"><span class="kw">SELECT</span> <span class="kw">id</span>, SNIPPET(title, <span class="kw">QUERY</span>()) <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>)</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2"><span class="kw">SELECT</span> <span class="kw">id</span>, SNIPPET(DOCUMENT(), <span class="kw">QUERY</span>()) <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>)</div>
<div class="sourceLine" id="3" href="#3" data-line-number="3"><span class="kw">SELECT</span> <span class="kw">id</span>, SNIPPET(DOCUMENT({title}), <span class="kw">QUERY</span>()) <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello&#39;</span>)</div></code></pre>
<p>Using <code>hl_fields</code> can accelerate highlighting where possible, sometimes making snippets <em>times</em> faster. If your documents are big enough (as in, a little bigger than tweets), try it! Without <code>hl_fields</code>, SNIPPET() function will have to reparse the document contents every time. With it, the parsed representation is compressed and stored into the index upfront, trading off a not-insignificant amount of CPU work for more disk space, and a few extra disk reads.</p>
<p>And speaking of disk space vs CPU tradeoff, these tweaking knobs let you fine-tune DocStore for specific indexes:</p>
<ul>
<li><code>docstore_type = vblock_solid</code> (default) groups small documents into a single compressed block, upto a given limit: better compression, slower access</li>
<li><code>docstore_type = vblock</code> stores every document separately: worse compression, faster access</li>
<li><code>docstore_block = 16k</code> (default) lets you tweak the block size limit</li>
<li><code>docstore_comp = lz4hc</code> (default) uses LZ4HC algorithm for compression: better compression, but slower</li>
<li><code>docstore_comp = lz4</code> uses LZ4 algorithm: worse compression, but faster</li>
<li><code>docstore_comp = none</code> disables compression</li>
</ul>
<h2 id="using-attribute-indexes">Using attribute indexes</h2>
<p>Quick kickoff: we now have <code>CREATE INDEX</code> statement, and sometimes it <em>does</em> make your queries faster!</p>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1"><span class="kw">CREATE</span> <span class="kw">INDEX</span> i1 <span class="kw">ON</span> mytest(<span class="fu">group_id</span>)</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2"><span class="kw">DESC</span> mytest</div>
<div class="sourceLine" id="3" href="#3" data-line-number="3"><span class="kw">SELECT</span> * <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> group_id=<span class="dv">1</span></div>
<div class="sourceLine" id="4" href="#4" data-line-number="4"><span class="kw">SELECT</span> * <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> <span class="fu">group_id</span> <span class="kw">BETWEEN</span> <span class="dv">10</span> <span class="kw">and</span> <span class="dv">20</span></div>
<div class="sourceLine" id="5" href="#5" data-line-number="5"><span class="kw">SELECT</span> * <span class="kw">FROM</span> mytest <span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello world&#39;</span>) <span class="kw">AND</span> group_id=<span class="dv">23</span></div>
<div class="sourceLine" id="6" href="#6" data-line-number="6"><span class="kw">DROP</span> <span class="kw">INDEX</span> i1 <span class="kw">ON</span> mytest</div></code></pre>
<p>Point reads, range reads, and intersections between <code>MATCH()</code> and index reads are all intended to work. Moreover, <code>GEODIST()</code> can also automatically use indexes (see more below). One of the goals is to completely eliminate the need to insert “fake keywords” into your index. (Also, it’s possible to <em>update</em> attribute indexes on the fly, as opposed to indexed text.)</p>
<p>Indexes on JSON keys should also work, but you might need to cast them to a specific type when creating the index:</p>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1"><span class="kw">CREATE</span> <span class="kw">INDEX</span> j1 <span class="kw">ON</span> mytest(j.group_id)</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2"><span class="kw">CREATE</span> <span class="kw">INDEX</span> j2 <span class="kw">ON</span> mytest(<span class="dt">INTEGER</span>(j.year))</div>
<div class="sourceLine" id="3" href="#3" data-line-number="3"><span class="kw">CREATE</span> <span class="kw">INDEX</span> j3 <span class="kw">ON</span> mytest(<span class="dt">FLOAT</span>(j.latitude))</div></code></pre>
<p>As of version 3.0.2, attribute indexes can only be created on RT indexes. However, you can <em>instantly</em> convert your plain indexes to RT by using <code>ATTACH ... WITH TRUNCATE</code>, and run <code>CREATE INDEX</code> after that, as follows:</p>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1">ATTACH <span class="kw">INDEX</span> myplain <span class="kw">TO</span> myrt <span class="kw">WITH</span> <span class="kw">TRUNCATE</span></div>
<div class="sourceLine" id="2" href="#2" data-line-number="2"><span class="kw">CREATE</span> <span class="kw">INDEX</span> date_added <span class="kw">ON</span> myrt(date_added)</div></code></pre>
<p>A rather important optimization of <code>GEODIST()</code> automatically kicks in when you (a) use the form with 2 columns and 2 constants, and (b) then use the result in a filter, as follows:</p>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1"><span class="kw">SELECT</span> *, GEODIST(lat,lon,<span class="fl">55.7540</span>,<span class="fl">37.6206</span>,{in=deg,out=km}) <span class="kw">AS</span> dist</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2">  <span class="kw">FROM</span> myindex <span class="kw">WHERE</span> dist&lt;=<span class="dv">100</span></div></code></pre>
<p>In this example, the query optimizer will automatically compute the approximate bounding box (i.e. minimum and maximum possible <code>lat</code> and <code>lon</code> values that are within the 100 km distance), and utilize the indexes on both <code>lat</code> and <code>lon</code> columns if they are available, and even intersect the index read results first if the indexes on <em>both</em> columns exist. For small distances (i.e. within one city or so), the speedup is usually huge. Also note that in a slightly different query the optimization might <em>not</em> trigger, for example:</p>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1"><span class="kw">SELECT</span> *, GEODIST(lat,lon,<span class="fl">55.7540</span>,<span class="fl">37.6206</span>,{in=deg,out=km})&lt;=<span class="dv">100</span> <span class="kw">AS</span> bad_dist_flag</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2">  <span class="kw">FROM</span> myindex <span class="kw">WHERE</span> bad_dist_flag=<span class="dv">1</span></div></code></pre>
<p>This is because the <code>WHERE</code> optimizer is a simpleton! It does not go too deep, and basically while in the first case it can immediately “sees” that <code>dist</code> is actually a <code>GEODIST()</code> and then examines it further, in the second case it only “sees” some kind of an arbitrary expression, and stops there.</p>
<p>TODO: describe more!</p>
<h2 id="using-k-batches">Using k-batches</h2>
<p>K-batches (“kill batches”) let you bulk delete older versions of the documents (rows) when bulk loading new data into Sphinx, for example, adding a new delta index on top of an older main archive index.</p>
<p>K-batches in Sphinx 3 replace k-lists (“kill lists”) from 2.x and before. The major differences are that:</p>
<ol type="1">
<li>They are <em>not</em> anonymous anymore.</li>
<li>They are now only applied once on loading. (As oppposed to every search, yuck).</li>
</ol>
<p>“Not anonymous” means that when loading a new index with an associated k-batch into <code>searchd</code>, <strong>you now have to explicitly specify target indexes</strong> that it should delete the rows from. In other words, “deltas” now <em>must</em> explicitly specify all the “main” indexes that they want to erase old documents from, at index-time.</p>
<p>The effect of applying a k-batch is equivalent to running (just once) a bunch of DELETE FROM X WHERE id=Y queries, for every index X listed in <code>kbatch</code> directive, and every document id Y stored in the k-batch. With the index format updates this is now both possible, <strong>even in “plain” indexes</strong>, and quite efficient too.</p>
<p>K-batch only gets applied once. After a succesful application to all the target indexes, the batch gets cleared.</p>
<p>So, for example, when you load an index called <code>delta</code> with the following settings:</p>
<pre><code>index delta
{
    ...
    sql_query_kbatch = SELECT 12 UNION SELECT 13 UNION SELECT 14
    kbatch = main1, main2
}</code></pre>
<p>The following (normally) happens:</p>
<ul>
<li><code>delta</code> kbatch file is loaded
<ul>
<li>in this example it will have 3 document ids: 12, 13, and 14</li>
</ul></li>
<li>documents with those ids are deleted from <code>main1</code></li>
<li>documents with those ids are deleted from <code>main2</code></li>
<li><code>main1</code>, <code>main2</code> save those deletions to disk</li>
<li>if all went well, <code>delta</code> kbatch file is cleared</li>
</ul>
<p>All these operations are pretty fast, because deletions are now internally implemented using a bitmap. So deleting a given document by id results in a hash lookup and a bit flip. In plain speak, very quick.</p>
<p>“Loading” can happen either by restarting or rotation or whatever, k-batches should still try to apply themselves.</p>
<p>Last but not least, you can also use <code>kbatch_source</code> to avoid explicitly storing all newly added document ids into a k-batch, instead, you can use <code>kbatch_source = kl, id</code> or just <code>kbatch_source = id</code>; this will automatically add all the document ids from the index to its k-batch. The default value is <code>kbatch_source = kl</code>, that is, to use explicitly provided docids only.</p>
<h2 id="doing-bulk-data-loads">Doing bulk data loads</h2>
<p>TODO: describe rotations (legacy), RELOAD, ATTACH, etc.</p>
<h2 id="using-json">Using JSON</h2>
<p>TODO: describe limits, key count impact, key compression, all the json_xxx settings, etc.</p>
<h2 id="indexing-csv-and-tsv-files">Indexing: CSV and TSV files</h2>
<p><code>indexer</code> supports indexing data in both CSV and TSV formats, via the <code>csvpipe</code> and <code>tsvpipe</code> source types, respectively. Here’s a brief cheat sheet on the respective source directives.</p>
<ul>
<li><code>csvpipe_command = ...</code> specifies a command to run (for instance, <code>csvpipe_command = cat mydata.csv</code> in the simplest case).</li>
<li><code>csvpipe_header = 1</code> tells the <code>indexer</code> to pick the column list from the first row (otherwise, by default, the column list has to be specified in the config file).</li>
<li><code>csvpipe_attr_XXX</code> (where <code>XXX</code> is an attribute type, i.e. one of <code>bigint</code>, <code>bool</code>, <code>float</code>, <code>json</code>, <code>multi</code>, <code>multi_64</code>, <code>string</code>, <code>timestamp</code>, or <code>uint</code>) specifies an attribute type for a given column.</li>
<li><code>csvpipe_field</code> and <code>csvpipe_field_string</code> specify a regular full-text field and a full-text field that should also be stored as a <code>string</code> attribute, respectively.</li>
<li><code>csvpipe_delimiter</code> changes the column delimiter to a given character (this is <code>csvpipe</code> only; <code>tsvpipe</code> naturally uses tabs).</li>
</ul>
<p>When working with TSV, you would use the very same directives, but start them with <code>tsvpipe</code> prefix (i.e. <code>tsvpipe_command</code>, <code>tsvpipe_header</code>, etc).</p>
<p>The first column is currently always treated as <code>id</code>, and must be a unique document identifier.</p>
<p>The first row can either be treated as a named list of columns (when <code>csvpipe_header = 1</code>), or as a first row of actual data. By default it’s treated as data. The column names are trimmed, so a bit of extra whitespace should not hurt.</p>
<p><code>csvpipe_header</code> affects how CSV input columns are matched to Sphinx attributes and fields.</p>
<p>With <code>csvpipe_header = 0</code> the input file only contains data, so the order of columns is taken from the config file. Thus, the order of <code>csvpipe_attr_XXX</code> and <code>csvpipe_field</code> directives is very important in this case. You will have to explicitly declare <em>all</em> the fields and attributes (except the leading <code>id</code>), and in <em>exactly</em> the same order they appear in the CSV file. <code>indexer</code> will warn if there were unmatched or extraneous columns.</p>
<p>With <code>csvpipe_header = 1</code> the input file starts with the column names list, so the declarations from the config file are only used to adjust the types. So in this case, the order of <code>csvpipe_attr_XXX</code> and <code>csvpipe_field</code> directives does not matter any more. Also, by default all the input CSV columns will be considered as fields, so you only need to explicitly configure attributes, not fields. For example, the following should work nicely, and index <code>title</code> and <code>content</code> as fields automatically:</p>
<pre><code>1.csv:

id, gid, title, content
123, 11, hello world, document number one
124, 12, hello again, document number two

sphinx.conf:

source csv1
{
    type = csvpipe
    csvpipe_command = cat 1.csv
    csvpipe_header = 1
    csvpipe_attr_uint = gid
}</code></pre>
<h2 id="indexing-special-chars-blended-tokens-and-mixed-codes">Indexing: special chars, blended tokens, and mixed codes</h2>
<p>Sphinx provides tools to help you better index (and then later search):</p>
<ul>
<li>terms that have special characters in them, like <code>@Rihanna</code>, or <code>Procter&amp;Gamble</code> or <code>U.S.A</code>, etc;</li>
<li>terms that mix letters and digits, like <code>UE53N5740AU</code>.</li>
</ul>
<p>The general approach, so-called “blending”, is the same in both cases:</p>
<ul>
<li>we always store a certain “base” (most granular) tokenization;</li>
<li>we also additonally store (“blend”) extra tokens, as configured;</li>
<li>we then let you search for either original or extra tokens.</li>
</ul>
<p>So in the examples just above Sphinx can:</p>
<ul>
<li>index base tokens, such as <code>rihanna</code> or <code>ue53n5740au</code>;</li>
<li>index special tokens, such as <code>@rihanna</code>;</li>
<li>index parts of mixed-codes tokens, such as <code>ue 53</code> and <code>ue53</code>.</li>
</ul>
<h3 id="blended-tokens-with-special-characters">Blended tokens (with special characters)</h3>
<p>To index <strong>blended tokens</strong>, i.e. tokens with special characters in them, you should:</p>
<ul>
<li>add your special “blended” characters to the <code>blend_chars</code> directive;</li>
<li>configure several processing modes for the extra tokens (optionally) using the <code>blend_mode</code> directive;</li>
<li>rebuild your index.</li>
</ul>
<p>Blended characters are going to be indexed both as separators, and <em>at the same time</em> as valid characters. They are considered separators when generating the base tokenization (or “base split” for short). But in addition they also are processed as valid characters when generating extra tokens.</p>
<p>For instance, when you set <code>blend_chars = @, &amp;, .</code> and index the text <code>@Rihanna Procter&amp;Gamble U.S.A</code>, the base split stores the following six tokens into the final index: <code>rihanna</code>, <code>procter</code>, <code>gamble</code>, <code>u</code>, <code>s</code>, and <code>a</code>. Exactly like it would without the <code>blend_chars</code>, based on just the <code>charset_table</code>.</p>
<p>And because of <code>blend_chars</code> settings, the following three <em>extra</em> tokens get stored: <code>@rihanna</code>, <code>procter&amp;gamble</code>, and <code>u.s.a</code>. Regular characters are still case-folded according to <code>charset_table</code>, but those special blended characters are now preserved. As opposed to being treated as whitespace, like they were in the base split. So far so good.</p>
<p>But why not just add <code>@, &amp;, .</code> to <code>charset_table</code> then? Because that way we would completely lose the base split. <em>Only</em> the three “magic” tokens like <code>@rihanna</code> would be stored. And then searching for their “parts” (for example, for just <code>rihanna</code> or just <code>gamble</code>) would not work. Meh.</p>
<p>Last but not least, the in-field token positions are adjusted accordingly, and shared between the base and extra tokens:</p>
<ul>
<li>pos 1, <code>rihanna</code> and <code>@rihanna</code></li>
<li>pos 2, <code>procter</code> and <code>procter&amp;gamble</code></li>
<li>pos 3, <code>gamble</code></li>
<li>pos 4, <code>u</code> and <code>u.s.a</code></li>
<li>pos 5, <code>s</code></li>
<li>pos 6, <code>a</code></li>
</ul>
<p>Bottom line, <code>blend_chars</code> lets you enrich the index and store extra tokens with special characters in those. That might be a handy addition to your regular tokenization based on <code>charset_table</code>.</p>
<h3 id="mixed-codes-with-letters-and-digits">Mixed codes (with letters and digits)</h3>
<p>To index <strong>mixed codes</strong>, i.e. terms that mix letters and digits, you need to enable <code>blend_mixed_codes = 1</code> setting (and reindex).</p>
<p>That way Sphinx adds extra spaces on <em>letter-digit boundaries</em> when making the base split, but still stores the full original token as an extra. For example, <code>UE53N5740AU</code> gets broken down to as much as 5 parts:</p>
<ul>
<li>pos 1, <code>ue</code> and <code>ue53n5740au</code></li>
<li>pos 2, <code>53</code></li>
<li>pos 3, <code>n</code></li>
<li>pos 4, <code>5740</code></li>
<li>pos 5, <code>au</code></li>
</ul>
<p>Besides the “full” split and the “original” code, it is also possible to store prefixes and suffixes. See <code>blend_mode</code> discussion just below.</p>
<p>Also note that on certain input data mixed codes indexing can generate a lot of undesired noise tokens. So when you have a number of fields with special terms that do <em>not</em> need to be processed as mixed codes (consider either terms like <code>_category1234</code>, or just long URLs), you can use the <code>mixed_codes_fields</code> directive and limit mixed codes indexing to human-readable text fields only. For instance:</p>
<pre><code>blend_mixed_codes = 1
mixed_codes_fields = title, content</code></pre>
<p>That could save you a noticeable amount of both index size and indexing time.</p>
<h3 id="blending-modes">Blending modes</h3>
<p>There’s somewhat more than one way to generate extra tokens. So there is a directive to control that. It’s called <code>blend_mode</code> and it lets you list all the different processing variants that you require:</p>
<ul>
<li><code>trim_none</code>, store a full token with all the blended characters;</li>
<li><code>trim_head</code>, store a token with heading blended characters trimmed;</li>
<li><code>trim_tail</code>, store a token with trailing blended characters trimmed;</li>
<li><code>trim_both</code>, store a token with both heading and trailing blended characters trimmed;</li>
<li><code>skip_pure</code>, do <em>not</em> store tokens that only contain blended characters;</li>
<li><code>prefix_tokens</code>, store all possible prefix tokens;</li>
<li><code>suffix_tokens</code>, store all possible suffix tokens.</li>
</ul>
<p>To visualize all those trims a bit, consider the following setup:</p>
<pre><code>blend_chars = @, !
blend_mode = trim_none, trim_head, trim_tail, trim_both

doc_title = @someone!</code></pre>
<p>Quite a bunch of extra tokens will be indexed in this case:</p>
<ul>
<li><code>someone</code> for the base split;</li>
<li><code>@someone!</code> for <code>trim_none</code>;</li>
<li><code>someone!</code> for <code>trim_head</code>;</li>
<li><code>@someone</code> for <code>trim_tail</code>;</li>
<li><code>someone</code> (yes, again) for <code>trim_both</code>.</li>
</ul>
<p><code>trim_both</code> option might seem redundant here for a moment. But do consider a bit more complicated term like <code>&amp;U.S.A!</code> where all the special characters are blended. It’s base split is three tokens (<code>u</code>, <code>s</code>, and <code>a</code>); it’s original full form (stored for <code>trim_none</code>) is lower-case <code>&amp;u.s.a!</code>; and so for this term <code>trim_both</code> is the only way to still generate the cleaned-up <code>u.s.a</code> variant.</p>
<p><code>prefix_tokens</code> and <code>suffix_tokens</code> actually begin to generate something non-trivial on that very same <code>&amp;U.S.A!</code> example, too. For the record, that’s because its base split is long enough, 3 or more tokens. <code>prefix_tokens</code> would be the only way to store the (useful) <code>u.s</code> prefix; and <code>suffix_tokens</code> would in turn store the (questionable) <code>s.a</code> suffix.</p>
<p>But <code>prefix_tokens</code> and <code>suffix_tokens</code> modes are, of course, especially useful for indexing mixed codes. The following gets stored with <code>blend_mode = prefix_tokens</code> in our running example:</p>
<ul>
<li>pos 1, <code>ue</code>, <code>ue53</code>, <code>ue53n</code>, <code>ue53n5740</code>, and <code>ue53n5740au</code></li>
<li>pos 2, <code>53</code></li>
<li>pos 3, <code>n</code></li>
<li>pos 4, <code>5740</code></li>
<li>pos 5, <code>au</code></li>
</ul>
<p>And with <code>blend_mode = suffix_tokens</code> respectively:</p>
<ul>
<li>pos 1, <code>ue</code> and <code>ue53n5740au</code></li>
<li>pos 2, <code>53</code> and <code>53n5740au</code></li>
<li>pos 3, <code>n</code> and <code>n5740au</code></li>
<li>pos 4, <code>5740</code> and <code>5740au</code></li>
<li>pos 5, <code>au</code></li>
</ul>
<p>Of course, there still can be missing combinations. For instance, <code>ue 53n</code> query will still not match any of that. However, for now we intentionally decided to avoid indexing <em>all</em> the possible base token subsequences, as that seemed to produce way too much noise.</p>
<h3 id="searching-vs-blended-tokens-and-mixed-codes">Searching vs blended tokens and mixed codes</h3>
<p>The rule of thumb is quite simple. All the extra tokens are <strong>indexing-only</strong>. And in queries, all tokens are treated “as is”.</p>
<p><strong>Blended characters</strong> are going to be handled as valid characters in the queries, and <em>require</em> matching.</p>
<p>For example, querying for <code>&quot;@rihanna&quot;</code> will <em>not</em> match <code>Robyn Rihanna Fenty is a Barbadian-born singer</code> document. However, querying for just <code>rihanna</code> will match both that document, and <code>@rihanna doesn't tweet all that much</code> document.</p>
<p><strong>Mixed codes</strong> are <em>not</em> going to be automatically “sliced” in the queries.</p>
<p>For example, querying for <code>UE53</code> will <em>not</em> automatically match neither <code>UE 53</code> nor <code>UE 37 53</code> documents. You need to manually add extra whitespace into your query term for that.</p>
<h2 id="ranking-idf-magics">Ranking: IDF magics</h2>
<p>Sphinx supports several different IDF (Inverse Document Frequency) calculation options. Those can affect your relevance ranking (aka scoring) when you are:</p>
<ul>
<li><em>either</em> sharding your data, even with built-in rankers;</li>
<li><em>or</em> doing any custom ranking work, even on a single shard.</li>
</ul>
<p>By default, term IDFs are (a) per-shard, and (b) computed online. So they might fluctuate significantly when ranking. And several other signals rely on them, so the entire rank might change a lot in a seeimingly random fashion. The reasons are twofold.</p>
<p>First, IDFs usually differ across shards (i.e. individual indexes that make up a bigger combined index). This means that a completely identical document might rank differently depending on a specific shard it ends up in. Not great.</p>
<p>Second, IDFs might change from query to query, as you update the index data. That instability in time might or might not be a desired effect.</p>
<p>To help alleviate these quirks (if they affect your use case), Sphinx offers two features:</p>
<ol type="1">
<li><code>local_df</code> option to aggregate sharded IDFs.</li>
<li><code>global_idf</code> feature to enforce prebuilt static IDFs.</li>
</ol>
<p><code>local_df</code> syntax is <code>SELECT ... OPTION local_df=1</code> and enabling that option tells the query to compute IDFs (more) precisely, i.e. over the entire index rather than individual shards. The default value is 0 (off) for performance reasons.</p>
<p><code>global_idf</code> feature is more complicated and includes several components:</p>
<ul>
<li><code>indextool --dumpdict --stats</code> switch that generates the source data, i.e. the per-shard dictionary dumps;</li>
<li><code>indextool --buildidf</code> switch that builds a static IDF file from those;</li>
<li>per-shard <code>global_idf</code> config directive that lets you assign a static IDF file to your shards;</li>
<li>per-query <code>OPTION global_idf=1</code> that forces the query to use that file.</li>
</ul>
<p>Both these features affect the input variables used for IDF calculations. More specifically:</p>
<ul>
<li>let <code>n</code> be the DF, document frequency (for a given term);</li>
<li>let <code>N</code> be the corpus size, total number of documents;</li>
<li>by default, both <code>n</code> and <code>N</code> are per-shard;</li>
<li>with <code>local_df</code>, they both are summed across shards;</li>
<li>with <code>global_idf</code>, they both are taken from a static IDF file.</li>
</ul>
<p>The static <code>global_idf</code> file actually stores a bunch of <code>n</code> values for every individual term, and the <code>N</code> value for the entire corpus, summed over all the source files that were available during <code>--buildidf</code> stage. For terms that are not present in the static <code>global_idf</code> file, their current (dynamic) DF values will be used. <code>local_df</code> should also still affect those.</p>
<p>To avoid overflows, <code>N</code> is adjusted up for the actual corpus size. Meaning that, for example, if the <code>global_idf</code> file says there were 1000 documents, but your index carries 3000 documents, then <code>N</code> is set to the bigger value, i.e. 3000. Therefore, you should either avoid using too small data slices for dictionary dumps, and/or manually adjust the frequencies, otherwise your static IDFs might be quite off.</p>
<p>To keep the <code>global_idf</code> file reasonably compact, you can use the additional <code>--skip-uniq</code> switch when doing the <code>--buildidf</code> stage. That switch will filter out all terms that only occur once. That usually reduces the <code>.idf</code> file size greatly, while still yielding exact or almost-exact results.</p>
<p>Coming up next, when computing IDFs from the <code>n</code> and <code>N</code> inputs, Sphinx also supports two IDF normalizations (one of them mostly for legacy reasons). Those can be set with <code>OPTION idf</code> in the <code>SELECT</code> statement.</p>
<ul>
<li>Sign normalization:
<ul>
<li><code>normalized</code>: BM25 variant, <code>raw_idf = log(N-n+1)</code>, as per Robertson;</li>
<li><code>plain</code>: plain variant, <code>raw_idf = log(N/n)</code>, as per Sparck-Jones.</li>
</ul></li>
<li>Legacy query range normalization:
<ul>
<li><code>tfidf_normalized</code>: <code>raw_idf = log(...) / query_word_count</code>;</li>
<li><code>tfidf_unnormalized</code>: <code>raw_idf = log(...)</code>.</li>
</ul></li>
</ul>
<p>And last but not least, to compute the final <code>idf</code> value from the intermediate <code>raw_idf</code> mentioned just above, Sphinx multiplies it by a couple more things:</p>
<ul>
<li><code>scaled_idf = raw_idf / (2*log(N+1))</code>
<ul>
<li>with <code>OPTION idf='normalized'</code> this gives <code>[-0.5, 0.5]</code> range;</li>
<li>with <code>OPTION idf='plain'</code> this gives <code>[0, 0.5]</code> range;</li>
<li>this is for compatibility with built-in rankers that expect that range.</li>
</ul></li>
<li><code>idf = scaled_idf * term_idf_boost</code>
<ul>
<li>this is, well, for query-time boosting of individual terms.</li>
</ul></li>
</ul>
<p>It is these final <code>idf</code> values that will be both used in the built-in rankers <em>and</em> reported via <code>FACTORS()</code> or passed to expression-based and UDF rankers (<code>OPTION ranker=expr(...)</code>). Yes, they are affected by all those options. Scary.</p>
<p>So what <code>OPTION idf</code> set to choose?! A quick rule of thumb is as follows:</p>
<ul>
<li>When using built-in rankers, just use the defaults.
<ul>
<li>Currently, the defaults are <code>OPTION idf='normalized,tfidf_normalized'</code></li>
</ul></li>
<li>When making your own ranker, switch to the opposite settings.
<ul>
<li>Specifically, use <code>OPTION idf='plain,tfidf_unnormalized'</code></li>
<li>Avoid using <code>tfidf_normalized</code> because it is slated for removal.</li>
<li>Also note that <code>atc</code> signal <em>only</em> produces expected results with these settings.</li>
</ul></li>
</ul>
<h2 id="ranking-picking-fields-with-rank_fields">Ranking: picking fields with <code>rank_fields</code></h2>
<p>When your indexes and queries contain any special “fake” keywords (usually used to speedup matching), it makes sense to exclude those from ranking. That can be achieved by putting such keywords into special fields, and then using <code>OPTION rank_fields</code> clause in the <code>SELECT</code> statement to pick the fields with actual text for ranking. For example:</p>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1"><span class="kw">SELECT</span> <span class="kw">id</span>, weight(), title <span class="kw">FROM</span> myindex</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2"><span class="kw">WHERE</span> MATCH(<span class="st">&#39;hello world @sys _category1234&#39;</span>)</div>
<div class="sourceLine" id="3" href="#3" data-line-number="3"><span class="kw">OPTION</span> rank_fields=<span class="st">&#39;title content&#39;</span></div></code></pre>
<p><code>rank_fields</code> is designed to work as follows. Only the keyword occurrences in the ranked fields get processed when computing ranking factors. Any other occurrences are ignored (by ranking, that is).</p>
<p>Note a slight caveat here: for <em>query-level</em> factors, only the <em>query</em> itself can be analyzed, not the index data.</p>
<p>This means that when you do not explicitly specify the fields in the query, the query parser <em>must</em> assume that the keyword can actually occur anywhere in the document. And, for example, <code>MATCH('hello world _category1234')</code> will compute <code>query_word_count=3</code> for that reason. This query does indeed have 3 keywords, even if <code>_category1234</code> never <em>actually</em> occurs anywhere except <code>sys</code> field.</p>
<p>Other than that, <code>rank_fields</code> is pretty straightforward. <em>Matching</em> will still work as usual. But for <em>ranking</em> purposes, any occurrences (hits) from the “system” fields can be ignored and hidden.</p>
<h2 id="changes-in-3.x">Changes in 3.x</h2>
<h3 id="version-3.1.1-17-oct-2018">Version 3.1.1, 17 oct 2018</h3>
<ul>
<li>added <code>indexer --dump-rows-tsv</code> switch, and renamed <code>--dump-rows</code> to <code>--dump-rows-sql</code></li>
<li>added initial <code>COALESCE()</code> function support for JSONs (beware that it will compute everything in floats!)</li>
<li>added support for <code>!=</code>, <code>IN</code>, and <code>NOT IN</code> syntax to expressions</li>
<li>added <code>prefix_tokens</code> and <code>suffix_tokens</code> options to <code>blend_mode</code> directive</li>
<li>added <code>OPTION rank_fields</code>, lets you specify fields to use for ranking with either expression or ML (UDF) rankers</li>
<li>added explicit duplicate documents (docids) suppression back into <code>indexer</code></li>
<li>added <code>batch_size</code> variable to <code>SHOW META</code></li>
<li>added <code>csvpipe_header</code> and <code>tsvpipe_header</code> directives</li>
<li>added <code>sql_xxx</code> counters to <code>SHOW STATUS</code>, generally cleaned up counters</li>
<li>added mixed codes indexing, available via <code>blend_mixed_codes</code> and <code>mixed_codes_fields</code> directives</li>
<li>added <code>OPTION inner_limit_per_index</code> to explicitly control reordering in a nested sharded select</li>
<li>added a hard limit for <code>max_matches</code> (must be under 100M)</li>
<li>optimized Postgres indexing CPU and RAM use quite significantly</li>
<li>optimized <code>FACET</code> queries with expressions and simple by-attribute (no aliases!) facets; multi-sort optmization now works in that case</li>
<li>optimized <code>id</code> lookups (queries like <code>UPDATE ... WHERE id=123</code> should now be much faster)</li>
<li>optimized result set aggregation vs nested sharded selects</li>
<li>optimized <code>PACKEDFACTORS()</code> storage a lot (upto 60x speedup with <code>max_matches=50000</code>)</li>
<li>improved UDF error handling, the error argument is now a message buffer instead of just a 1-char flag</li>
<li>improved the nested sharded select reordering, less confusing now (by default, does <em>not</em> scale the inner <code>LIMIT</code> anymore)</li>
<li>improved <code>searchd --listen</code> switch, multiple <code>--listen</code> instances are now allowed, and <code>--console</code> is <em>not</em> required anymore</li>
<li>improved failed allocation reporting, and added huge allocation tracking</li>
<li>removed legacy <code>@count</code>, <code>@weight</code>, <code>@expr</code>, <code>@geodist</code> syntax support</li>
<li>removed legacy <code>SetWeights()</code>, <code>SetMatchMode()</code>, <code>SetOverride()</code>, <code>SetGeoAnchor()</code> calls, <code>SPH_MATCH_xxx</code> constants, and <code>SPH_SORT_EXPR</code> sorting mode from APIs</li>
<li>removed legacy <code>spelldump</code> utility</li>
<li>removed unused <code>.sha</code> index files</li>
<li>removed extraneous “no extra index definitions” warning</li>
</ul>
<p>Major fixes:</p>
<ul>
<li>fixed 9+ crashes caused by certain complex (and usually rare) conditions and/or settings combinations</li>
<li>fixed 2 crashes caused by broken index data (in vrows and dictionaries)</li>
<li>fixed plain index locking issues on Windows</li>
<li>fixed JSON fields handling vs strings and NULLs (no more corner cases like NULL objects passing a test for json.col=0)</li>
<li>fixed matches loss issue in positional (phrase/order/sentence etc) operators and modifiers under certain conditions</li>
<li>fixed hashing-related hangups under certain (rather rare) occasions</li>
<li>fixed several type inference issues in expressions when using JSON fields</li>
</ul>
<p>Other fixes:</p>
<ul>
<li>fixed that <code>min_best_span_pos</code> was sometimes off</li>
<li>fixed the behavior on missing <code>global_idf</code> file</li>
<li>fixed <code>indextool --check</code> vs string attributes, and vs empty JSONs</li>
<li>fixed blended vs multiforms behavior (works much more predictably now)</li>
<li>fixed query parser vs wildcard-only tokens</li>
<li>fixed that MySQL 8.0+ clients failed to connect</li>
<li>fixed occasional semaphore races on startup</li>
<li>fixed <code>OPTIMIZE</code> vs <code>UPDATE</code> race; <code>UPDATE</code> can now fail with a timeout</li>
<li>fixed <code>indexer --merge --rotate</code> vs kbatches</li>
<li>fixed occasional rotation-related deadlock</li>
<li>fixed a few memory leaks</li>
</ul>
<h3 id="version-3.0.3-30-mar-2018">Version 3.0.3, 30 mar 2018</h3>
<ul>
<li>added <code>BITCOUNT()</code> function and bitwise-NOT operator, eg <code>SELECT BITCOUNT(~3)</code></li>
<li>made <code>searchd</code> config section completely optional</li>
<li>improved <code>min_infix_len</code> behavior, required 2-char minimum is now enforced</li>
<li>improved docs, added a few sections</li>
<li>fixed binary builds performance</li>
<li>fixed several crashes (related to docstore, snippets, threading, <code>json_packed_keys</code> in RT)</li>
<li>fixed docid-less SQL sources, forbidden those for now (docid still required)</li>
<li>fixed int-vs-float precision issues in expressions in certain cases</li>
<li>fixed <code>uptime</code> counter in <code>SHOW STATUS</code></li>
<li>fixed query cache vs <code>PACKEDFACTORS()</code></li>
</ul>
<h3 id="version-3.0.2-25-feb-2018">Version 3.0.2, 25 feb 2018</h3>
<ul>
<li>added <code>full_field_hit</code> ranking factor</li>
<li>added <code>bm15</code> ranking factor name (legacy <code>bm25</code> name misleading, to be removed)</li>
<li>optimized RT inserts significantly (upto 2-6x on certain benchmarks vs 3.0.1)</li>
<li>optimized <code>exact_field_hit</code> ranking factor, impact now negligible (approx 2-4%)</li>
<li>improved <code>indexer</code> output, less visual noise</li>
<li>improved <code>searchd --safetrace</code> option, now skips <code>addr2line</code> to avoid occasional freezes</li>
<li>improved <code>indexer</code> MySQL driver lookup, now also checking for <code>libmariadb.so</code></li>
<li>fixed rare occasional <code>searchd</code> crash caused by attribute indexes</li>
<li>fixed <code>indexer</code> crash on missing SQL drivers, and improved error reporting</li>
<li>fixed <code>searchd</code> crash on multi-index searches with docstore</li>
<li>fixed that expression parser failed on field-shadowing attributes in <code>BM25F()</code> weights map</li>
<li>fixed that <code>ALTER</code> failed on field-shadowing attributes vs <code>index_field_lengths</code> case</li>
<li>fixed junk data writes (seemingly harmless but anyway) in certain cases</li>
<li>fixed rare occasional <code>searchd</code> startup failures (threading related)</li>
</ul>
<h3 id="version-3.0.1-18-dec-2017">Version 3.0.1, 18 dec 2017</h3>
<ul>
<li>first public release of 3.x branch</li>
</ul>
<h2 id="changes-since-2.x">Changes since 2.x</h2>
<blockquote>
<p>WIP: the biggest change to rule them all is yet to come. The all new, fully RT index format is still in progress, and not yet available. Do not worry, ETL via <code>indexer</code> will <em>not</em> be going anywhere. Moreover, despite being fully and truly RT, the new format is actually already <em>faster</em> at batch indexing.</p>
</blockquote>
<p>The biggest changes since Sphinx 2.x are:</p>
<ul>
<li>added DocStore, document storage
<ul>
<li>original document contents can now be stored into the index</li>
<li>disk based storage, RAM footprint should be minimal</li>
<li>goodbye, <em>having</em> to query Another Database to fetch data</li>
</ul></li>
<li>added new attributes storage format
<ul>
<li>arbitrary updates support (including MVA and JSON)</li>
<li>goodbye, sudden size limits</li>
</ul></li>
<li>added attribute indexes, with JSON support
<ul>
<li>… <code>WHERE gid=123</code> queries can now utilize A-indexes</li>
<li>… <code>WHERE MATCH('hello') AND gid=123</code> queries can now efficiently intersect FT-indexes and A-indexes</li>
<li>goodbye, <em>having</em> to use fake keywords</li>
</ul></li>
<li>added compressed JSON keys</li>
<li>switched to rowids internally, and forced all docids to 64 bits</li>
</ul>
<p>Another two big changes that are already available but still in pre-alpha are:</p>
<ul>
<li>added “zero config” mode (<code>./sphinxdata</code> folder)</li>
<li>added index replication</li>
</ul>
<p>The additional smaller niceties are:</p>
<ul>
<li>added always-on support for xmlpipe, snowball stemmers, and re2 (regexp filters)</li>
<li>added <code>blend_mode=prefix_tokens</code>, and enabled empty <code>blend_mode</code></li>
<li>added <code>kbatch_source</code> directive, to auto-generate k-batches from source docids (in addition to explicit queries)</li>
<li>added <code>SHOW OPTIMIZE STATUS</code> statement</li>
<li>added <code>exact_field_hit</code> ranking factor</li>
<li>added <code>123.45f</code> value syntax in JSON, optimized support for float32 vectors, and <code>FVEC()</code> and <code>DOT()</code> functions</li>
<li>added preindexed data in document storage to speed up <code>SNIPPETS()</code> (via <code>hl_fields</code> directive)</li>
<li>changed field weights, zero and negative weights are now allowed</li>
<li>changed stemming, keywords with digits are now excluded</li>
</ul>
<p>A bunch of legacy things were removed:</p>
<ul>
<li>removed <code>dict</code>, <code>docinfo</code>, <code>infix_fields</code>, <code>prefix_fields</code> directives</li>
<li>removed <code>attr_flush_period</code>, <code>hit_format</code>, <code>hitless_words</code>, <code>inplace_XXX</code>, <code>max_substring_len</code>, <code>mva_updates_pool</code>, <code>phrase_boundary_XXX</code>, <code>sql_joined_field</code>, <code>subtree_XXX</code> directives</li>
<li>removed legacy id32 and id64 modes, mysqlSE plugin, and <code>indexer --keep-attrs</code> switch</li>
</ul>
<p>And last but not least, the new config directives to play with are:</p>
<ul>
<li><code>docstore_type</code>, <code>docstore_block</code>, <code>docstore_comp</code>, <code>docstore_cache_size</code> (per-index) let you generally configure DocStore</li>
<li><code>stored_fields</code>, <code>stored_only_fields</code>, <code>hl_fields</code> (per-index) let you configure what to put in DocStore</li>
<li><code>kbatch</code>, <code>kbatch_source</code> (per-index) update the legacy k-lists-related directives</li>
<li><code>updates_pool</code> (per-index) sets vrow file growth step</li>
<li><code>json_packed_keys</code> (<code>common</code> section) enables the JSON keys compression</li>
<li><code>binlog_flush_mode</code> (<code>searchd</code> section) changes the per-op flushing mode (0=none, 1=fsync, 2=fwrite)</li>
</ul>
<p>Quick update caveats:</p>
<ul>
<li>if you were using <code>sql_query_killlist</code> then you now <em>must</em> explicitly specify <code>kbatch</code> and list all the indexes that the k-batch should be applied to:</li>
</ul>
<pre class="sourceCode sql"><code class="sourceCode sql"><div class="sourceLine" id="1" href="#1" data-line-number="1">sql_query_killlist = <span class="kw">SELECT</span> deleted_id <span class="kw">FROM</span> my_deletes_log</div>
<div class="sourceLine" id="2" href="#2" data-line-number="2">kbatch = main</div>
<div class="sourceLine" id="3" href="#3" data-line-number="3"></div>
<div class="sourceLine" id="4" href="#4" data-line-number="4"># <span class="kw">or</span> perhaps:</div>
<div class="sourceLine" id="5" href="#5" data-line-number="5"># kbatch = shard1,shard2,shard3,shard4</div></code></pre>
<h2 id="copyrights">Copyrights</h2>
<p>This documentation is copyright (c) 2017-2018, Andrew Aksyonoff. The author hereby grants you the right to redistribute it in a verbatim form, along with the respective copy of Sphinx it came bundled with. All other rights are reserved.</p>
</body>
</html>
