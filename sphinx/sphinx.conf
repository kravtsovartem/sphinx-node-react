# Источник данных — MSSQL
# В конфиге источники могут наследоваться. создадим базовый конфиг для любых MSSQL-источников
# чтобы не копипастить данные для подключения
source base
{
    type            = mssql
    sql_host        = localhost\SQLEXPRESS01
    sql_user        = 
    sql_pass        = 
    sql_db          = wt_data
    sql_port        = 1433 
	
	mssql_winauth = 1
	mssql_unicode = 1

    # Ставим кодировку при соединении
}

# Теперь настроим источник данных для выборки новостей наследующийся от базового
source src_news: base
{
    # Включаем range (выборку больших таблиц по частям)
    # sql_range_step          = 1000

    # запрос на выборку диапазона id
    # sql_query_range         = SELECT MIN(id), MAX(id) FROM news


    # Библиотека материалов из WebTutor
	# parent_object_id = 6713105597108530952 - Родительская категория
    sql_query       = \
				WITH Recursive (id) \
				AS \
				( \
					SELECT \
						id \
					FROM \
						library_sections \
					WHERE \
						parent_object_id = 6713105597108530952 \
					UNION ALL \
					SELECT \
						Libs.id \
					FROM \
						library_sections Libs \
						JOIN Recursive R ON R.id = Libs.parent_object_id \
				) \
					\
				SELECT \
				 * \
				FROM ( \
					SELECT \
						LibData.id, \
						CAST(LibData.id as nvarchar(max)) uid, \
						Lib.name, \
						LibData.data.value('(library_material/contents)[1]', 'nvarchar(max)') text \
					FROM \
						library_material LibData \
					JOIN \
						library_materials Lib ON Lib.id = LibData.id \
					WHERE \
						Lib.section_id IN ( \
							SELECT \
								id \
							FROM \
								Recursive \
						) \
				) TEMP \
				WHERE \
					text IS NOT NULL \
			
	#sql_query       = \
	#		SELECT \
	#			id, \
	#			CAST(id as nvarchar(max)) uid, \
	#			name, \
	#			text \
	#		FROM \
	#			mytable
	
	sql_field_string = uid
	sql_field_string = name
	sql_field_string = text
}

# Теперь создаем индекс из данных взятых из источника
index index_news
{
    source = src_news
    # где хранить данные
    # не знаю, как писать относительный путь, потому пишу абсолютный
    path = D:/Projects/NodeJS/SphinxSearch/sphinx/data/index/news
    # где хранить аттрибуты — в индексе (inline) или отдельном файле (extern)
    docinfo = extern
	# Тип словаря, crc или keywords. crc лучше использовать когда не нужен поиск по подстрокам. Keywords быстрее работает с подстроками,
	# поддерживает wildcard поиск и размер индекса получается в 3-10 раз меньше.
	# При включении dict автоматически игнорируется директива min_infix_len
	dict = keywords
    # Либо sbcs (1-байтовая кодировка) либо utf-8
    charset_type    = utf-8
	
    morphology  = lemmatize_ru_all, lemmatize_en_all, stem_enru, soundex, metaphone
	
	# Позволяет использовать звездочки в запросах, к примеру по запросу *пр* будут найдены проспект, привет, апроксимация и др.
    enable_star = 1
	
	# К примеру при min_infix_len = 2 и попаданию в индекс слова “тест”, будут сохранены в индекс “те”, “ес”, “ст”, “тес”, “ест”, 
	# “тест” и по запросу “ес” будет найдено это слово.
	# Cильно увеличивает индекс.
    # min_infix_len   = 2
	# Является дочерним для min_infix_len и делает почти тоже самое только сохраняет начало слов или префиксы. Cлова “тест”, будут сохранены в индекс “те”, “тес”
	min_prefix_len    = 3
	# Минимальный размер слова для индексации, по умолчанию 1 и индексирует все слова.
	min_word_len = 3
	
	# Вырезает все html теги и html комментарии.
	html_strip				= 1
	
	# Автоматически расширяет поисковый запрос до трех запросов running -> ( running | *running* | =running )
	expand_keywords = 1
	# Позволяет на ряду с морфологически нормализованной формой хранить и оригинальное слово в индексе.
	# Это сильно увеличивает размер индекса, но с учетом предыдущей опции позволяет выдавать результаты более релевантно.
	index_exact_words = 1
	
	
	charset_table = 0..9, A..Z->a..z, _, a..z, \
    U+410..U+42F->U+430..U+44F, U+430..U+44F, U+401->U+0435, U+451->U+0435
	
	blend_chars = +, U+23
	ignore_chars = U+AD	
}

# Говорим сколько памяти можно использовать при индексации (если недодать то будет ошибка)
# объем памяти зависит от размера таблицы и опредеояется опытным путем
indexer
{
    mem_limit       = 350M
}

common {
    lemmatizer_base = data/dicts
}

# настройки поискового демона
searchd
{
    # на каких портах слушать с бинарным протоколом
    listen          = 9312
    # и с mysql-протоколом
    listen          = 9306:mysql41

    # Куда класть логи
    log         = data/log/searchd.log
    query_log       = data/log/query.log
    pid_file        = data/log/searchd.pid
    binlog_path     = data/biglog/

	# тайм-аут чтения в секундах.
    read_timeout        = 5
	#  максимальное количество форков.
    max_children        = 30
    max_matches     = 1000
    seamless_rotate     = 1
    preopen_indexes     = 1
    unlink_old      = 1
    workers         = threads # for RT to work
}